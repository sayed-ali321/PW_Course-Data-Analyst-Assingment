{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "### Theoretical Question's\n",
        "\n",
        "1. What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "\n",
        "Answer: Logistic Regression is used for classification tasks (predicting categories like yes/no), while Linear Regression is used for regression (predicting continuous values). Logistic Regression predicts probabilities using a sigmoid function, while Linear Regression predicts real-valued outputs.\n",
        "\n",
        "2. What is the mathematical equation of Logistic Regression?\n",
        "\n",
        "Answer:\n",
        "The general equation is:\n",
        "P(Y=1 | X) = 1 / (1 + exp(-(β₀ + β₁X₁ + β₂X₂ + ... + βnXn)) )\n",
        "Where:\n",
        "P(Y=1 | X): is the probability of Y=1 (the event of interest) given the input features X.\n",
        "β₀, β₁, β₂, ..., βn: are the coefficients or weights associated with each input feature X₁, X₂, ..., Xn.\n",
        "X₁, X₂, ..., Xn: are the input features or independent variables.\n",
        "exp(): is the exponential function (e^x).\n",
        "\n",
        "3. Why do we use the Sigmoid function in Logistic Regression?\n",
        "\n",
        "Answer: The sigmoid function maps any real-valued number into a range between 0 and 1, making it suitable for predicting probabilities.\n",
        "\n",
        "4. What is the cost function of Logistic Regression?\n",
        "\n",
        "Answer:\n",
        "Formula:\n",
        "The Log Loss for a single data point (x, y) is:\n",
        "-y * log(h(x)) - (1 - y) * log(1 - h(x))\n",
        "Where:\n",
        "y is the actual class label (0 or 1)\n",
        "h(x) is the predicted probability (output of the sigmoid function)\n",
        "\n",
        "\n",
        "5. What is Regularization in Logistic Regression? Why is it needed?\n",
        "\n",
        "Answer: Regularization adds a penalty to the cost function to prevent overfitting. It helps the model generalize better to new data.\n",
        "\n",
        "\n",
        "6. Explain the difference between Lasso, Ridge, and Elastic Net regression.\n",
        "\n",
        "Answer:\n",
        "\n",
        "Lasso (L1): Shrinks some coefficients to zero (feature selection).\n",
        "\n",
        "Ridge (L2): Shrinks coefficients smoothly but none become exactly zero.\n",
        "\n",
        "Elastic Net: Combines L1 and L2, balancing sparsity and stability.\n",
        "\n",
        "\n",
        "\n",
        "7. When should we use Elastic Net instead of Lasso or Ridge?\n",
        "\n",
        "Answer: Use Elastic Net when you have many correlated features and want both feature selection and model stability.\n",
        "\n",
        "\n",
        "8. What is the impact of the regularization parameter (λ) in Logistic Regression?\n",
        "\n",
        "Answer: Higher λ increases regularization strength, reducing overfitting but may underfit if too high. Lower λ reduces regularization, risking overfitting.\n",
        "\n",
        "\n",
        "\n",
        "9. What are the key assumptions of Logistic Regression?\n",
        "\n",
        "Answer:\n",
        "\n",
        "The outcome is binary (or multinomial with extensions).\n",
        "\n",
        "Linear relationship between independent variables and log-odds.\n",
        "\n",
        "No multicollinearity among predictors.\n",
        "\n",
        "Independence of observations.\n",
        "\n",
        "Large sample size for stable estimates.\n",
        "\n",
        "\n",
        "\n",
        "10. What are some alternatives to Logistic Regression for classification tasks?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Decision Trees\n",
        "\n",
        "Random Forests\n",
        "\n",
        "Support Vector Machines (SVM)\n",
        "\n",
        "k-Nearest Neighbors (k-NN)\n",
        "\n",
        "Naive Bayes\n",
        "\n",
        "Neural Networks\n",
        "\n",
        "\n",
        "\n",
        "11. What are Classification Evaluation Metrics?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Accuracy\n",
        "\n",
        "Precision\n",
        "\n",
        "Recall\n",
        "\n",
        "F1-Score\n",
        "\n",
        "ROC-AUC\n",
        "\n",
        "Confusion Matrix\n",
        "\n",
        "\n",
        "12. How does class imbalance affect Logistic Regression?\n",
        "\n",
        "Answer: It can cause the model to favor the majority class, leading to misleading accuracy. Metrics like precision, recall, and F1-score are better in such cases.\n",
        "\n",
        "\n",
        "13. What is Hyperparameter Tuning in Logistic Regression?\n",
        "\n",
        "Answer: It involves selecting the best model parameters (like regularization strength, type of penalty, solver) using techniques like grid search or cross-validation.\n",
        "\n",
        "\n",
        "14. What are different solvers in Logistic Regression? Which one should be used?\n",
        "\n",
        "Answer:\n",
        "\n",
        "liblinear: Good for small datasets, supports L1.\n",
        "\n",
        "saga: Good for large datasets, supports L1 and Elastic Net.\n",
        "\n",
        "lbfgs: Fast for L2 penalty, best for multiclass.\n",
        "\n",
        "Choose based on dataset size and regularization type.\n",
        "\n",
        "\n",
        "\n",
        "15. How is Logistic Regression extended for multiclass classification?\n",
        "\n",
        "Answer:\n",
        "\n",
        "One-vs-Rest (OvR): One classifier per class.\n",
        "\n",
        "Multinomial (Softmax Regression): Single model predicting probabilities across classes.\n",
        "\n",
        "\n",
        "\n",
        "16. What are the advantages and disadvantages of Logistic Regression?\n",
        "\n",
        "Answer:\n",
        "Advantages:\n",
        "\n",
        "Simple and easy to implement\n",
        "\n",
        "Works well with linearly separable data\n",
        "\n",
        "Provides probabilities\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Assumes linearity in log-odds\n",
        "\n",
        "Struggles with non-linear relationships\n",
        "\n",
        "Sensitive to outliers and irrelevant features\n",
        "\n",
        "\n",
        "\n",
        "17. What are some use cases of Logistic Regression?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Email spam detection\n",
        "\n",
        "Disease diagnosis\n",
        "\n",
        "Credit scoring\n",
        "\n",
        "Customer churn prediction\n",
        "\n",
        "Click-through rate prediction\n",
        "\n",
        "\n",
        "\n",
        "18. What is the difference between Softmax Regression and Logistic Regression?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Logistic Regression: Binary classification.\n",
        "\n",
        "Softmax Regression: Generalization to multiclass classification by using softmax instead of sigmoid.\n",
        "\n",
        "\n",
        "19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Use OvR for simplicity or when classes are imbalanced.\n",
        "\n",
        "Use Softmax for direct multiclass probability estimates and when using solvers that support it.\n",
        "\n",
        "\n",
        "20. How do we interpret coefficients in Logistic Regression?\n",
        "\n",
        "Answer:\n",
        "Each coefficient represents the change in log-odds of the outcome for a one-unit increase in the predictor, holding others constant. Exponentiating the coefficient gives the odds ratio."
      ],
      "metadata": {
        "id": "-91ZTCVU9iRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practical"
      ],
      "metadata": {
        "id": "WvTk6pkAESmS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6K_ZVw2z6xae",
        "outputId": "0fd3a28e-2409-47ce-92f9-3f65360fdb87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9737\n"
          ]
        }
      ],
      "source": [
        "#1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load sample dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Fit logistic regression with increased max_iter\n",
        "model = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear', C=1.0, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(f\"L1 Regularization Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KnwCBhYFgOx",
        "outputId": "be2a83c5-bafe-4a94-bb5e-051eafdbd421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 Regularization Accuracy: 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients\n",
        "\n",
        "# Load data\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train logistic regression with L2 regularization\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Output accuracy and coefficients\n",
        "print(f\"L2 Regularization Accuracy: {model.score(X_test_scaled, y_test):.4f}\")\n",
        "print(\"Coefficients:\", model.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7BGlqVSJHPN",
        "outputId": "c3367013-77f0-41cf-f600-9ae17a0a47b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 Regularization Accuracy: 0.9737\n",
            "Coefficients: [[-0.43190368 -0.38732553 -0.39343248 -0.46521006 -0.07166728  0.54016395\n",
            "  -0.8014581  -1.11980408  0.23611852  0.07592093 -1.26817815  0.18887738\n",
            "  -0.61058302 -0.9071857  -0.31330675  0.68249145  0.17527452 -0.3112999\n",
            "   0.50042502  0.61622993 -0.87984024 -1.35060559 -0.58945273 -0.84184594\n",
            "  -0.54416967  0.01611019 -0.94305313 -0.77821726 -1.20820031 -0.15741387]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Elastic Net Logistic Regression\n",
        "model = LogisticRegression(\n",
        "    penalty='elasticnet',\n",
        "    solver='saga',        # required for elasticnet\n",
        "    l1_ratio=0.5,         # mix of L1 and L2\n",
        "    C=1.0,\n",
        "    max_iter=2000,        # increased from 1000\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "print(f\"Elastic Net Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86NHaAW0Xjsf",
        "outputId": "1768156c-0e28-49c4-a9e7-23915d9baade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elastic Net Accuracy: 0.9737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# One-vs-Rest Logistic Regression\n",
        "base_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "model = OneVsRestClassifier(base_model)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Multiclass OvR Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Iaq5jYPYGOr",
        "outputId": "77877885-b3da-4bbc-8366-8d40b6ddd476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass OvR Accuracy: 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best Parameters: {grid.best_params_}\")\n",
        "print(f\"Best Accuracy: {grid.best_score_:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br2fi0J_YlSa",
        "outputId": "51ca78ac-55b3-4594-95aa-ecb687ccc70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Accuracy: 0.9583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "print(f\"Average Stratified K-Fold Accuracy: {scores.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mApjwv41ZPft",
        "outputId": "5ab185a7-3725-4ae8-bb93-0fbc853e3e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Stratified K-Fold Accuracy: 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "7HL3NGjDbGA6",
        "outputId": "a0cc8d7b-3d77-4b36-dded-87f2633d5b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a586e188-b484-4657-9c77-cb8fdd7014dd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a586e188-b484-4657-9c77-cb8fdd7014dd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Hospital_Data.csv to Hospital_Data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv('Hospital_Data.csv')\n",
        "\n",
        "# Convert Medical Expenses into binary classification target\n",
        "df['High Expense'] = (df['Medical Expenses'] > df['Medical Expenses'].median()).astype(int)\n",
        "target_col = 'High Expense'\n",
        "\n",
        "# Drop irrelevant or non-numeric columns\n",
        "df = df.drop(['Hospital Name', 'Location', 'Department', 'Admission Date', 'Discharge Date'], axis=1)\n",
        "\n",
        "# Split features and target\n",
        "X = df.drop(target_col, axis=1)\n",
        "y = df[target_col]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train logistic regression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate\n",
        "accuracy = model.score(X_test_scaled, y_test)\n",
        "print(f\"CSV Dataset Accuracy: {accuracy:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7AmkbP7Zcyu",
        "outputId": "fc3eab22-ce48-4cc4-8ac2-7630d7219305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV Dataset Accuracy: 0.9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "# Optional: Suppress convergence warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define parameter grid\n",
        "param_dist = {\n",
        "    'C': np.logspace(-3, 3, 10),\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "# Logistic Regression with high iteration limit\n",
        "model = LogisticRegression(max_iter=5000)\n",
        "\n",
        "# RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit model\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Output results\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(f\"Best Accuracy: {random_search.best_score_:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq6UjZ1JZheO",
        "outputId": "5d7f94f0-ee99-4fae-8a13-801d60e1be98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': np.float64(0.46415888336127775)}\n",
            "Best Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy\n",
        "\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "ovo_model = OneVsOneClassifier(LogisticRegression(max_iter=1000))\n",
        "ovo_model.fit(X_train, y_train)\n",
        "\n",
        "print(f\"OvO Accuracy: {ovo_model.score(X_test, y_test):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WznTcAxNdtES",
        "outputId": "9d31474d-7332-4e53-fe31-730bda3359d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OvO Accuracy: 0.9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification\n",
        "\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "UkCwx4isdwo-",
        "outputId": "b6a03959-141b-45db-f5c3-d4ebdf05852b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7d9f4ec2f490>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRIEXiCQd02D",
        "outputId": "611daff2-a0b3-4c62-f86e-5b62505b0120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9166666666666666\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9565217391304348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance\n",
        "\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Balanced Accuracy: {model.score(X_test, y_test):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlq7h4z-eC88",
        "outputId": "44b3ed4f-124a-4c82-d455-bb6928e2b3bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced Accuracy: 0.9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "titanic = sns.load_dataset('titanic').dropna(subset=['age', 'embarked', 'sex', 'fare', 'pclass', 'survived'])\n",
        "titanic['sex'] = titanic['sex'].map({'male': 0, 'female': 1})\n",
        "titanic['embarked'] = titanic['embarked'].astype('category').cat.codes\n",
        "\n",
        "X = titanic[['age', 'fare', 'pclass', 'sex', 'embarked']]\n",
        "y = titanic['survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Titanic Dataset Accuracy: {model.score(X_test, y_test):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb51_7MZeIl6",
        "outputId": "c475e83d-455d-4687-dece-09b66a0e0675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Titanic Dataset Accuracy: 0.7902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train_s, X_test_s, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_s, y_train)\n",
        "\n",
        "model_unscaled = LogisticRegression(max_iter=1000)\n",
        "model_unscaled.fit(X_train, y_train)\n",
        "\n",
        "print(f\"With Scaling: {model_scaled.score(X_test_s, y_test):.4f}\")\n",
        "print(f\"Without Scaling: {model_unscaled.score(X_test, y_test):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbJMThFNePZA",
        "outputId": "dcc782a8-0d4f-4533-f480-ea8f4c3ffbda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With Scaling: 0.7902\n",
            "Without Scaling: 0.7902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0vkak58eXYS",
        "outputId": "60f004a0-f7aa-489e-f3ce-5a1d34368cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.8176587301587303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy\n",
        "\n",
        "model = LogisticRegression(C=0.5, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Custom C=0.5 Accuracy: {model.score(X_test, y_test):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2TjZfc5ecuK",
        "outputId": "eb4e15a9-a541-42b6-84b0-c0b04b315a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom C=0.5 Accuracy: 0.7972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 18. Write a Python program to train Logistic Regression and identify important features based on model coefficients\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "importance = np.abs(model.coef_[0])\n",
        "feature_names = X.columns\n",
        "\n",
        "for name, coef in sorted(zip(feature_names, importance), key=lambda x: -x[1]):\n",
        "    print(f\"{name}: {coef:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLNB-9kBeg9q",
        "outputId": "15403905-4089-4415-f1c4-af78a7b157d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sex: 2.3640\n",
            "pclass: 1.2727\n",
            "embarked: 0.1439\n",
            "age: 0.0301\n",
            "fare: 0.0020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa Score\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Cohen's Kappa Score:\", cohen_kappa_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlfNSic5el0K",
        "outputId": "e584122d-3e9b-4098-877e-b6b5599edc4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: 0.5764477581452354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
        "disp.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "3e9lnu4EepWG",
        "outputId": "6af863e0-4241-48b9-a0b2-f71e0365bcf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x7d9f4db36110>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy\n",
        "\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    print(f\"Solver: {solver}, Accuracy: {model.score(X_test, y_test):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPrV_FBveukO",
        "outputId": "edbcc549-6929-4ba0-a9ea-52633d80a142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solver: liblinear, Accuracy: 0.7832\n",
            "Solver: saga, Accuracy: 0.6643\n",
            "Solver: lbfgs, Accuracy: 0.7902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC)\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z70UW2JezvB",
        "outputId": "8ac130fb-f5b0-459d-e9f4-107042da2a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient: 0.5785646390943534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling\n",
        "\n",
        "model_raw = LogisticRegression(max_iter=1000)\n",
        "model_raw.fit(X_train, y_train)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_s, y_train)\n",
        "\n",
        "print(f\"Raw Accuracy: {model_raw.score(X_test, y_test):.4f}\")\n",
        "print(f\"Scaled Accuracy: {model_scaled.score(X_test_s, y_test):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgqG4OrQe3uR",
        "outputId": "240f06ae-deef-444a-f2d2-29780e7c20e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Accuracy: 0.7902\n",
            "Scaled Accuracy: 0.7902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "Cs = [0.01, 0.1, 1, 10, 100]\n",
        "for c in Cs:\n",
        "    model = LogisticRegression(C=c, max_iter=1000)\n",
        "    scores = cross_val_score(model, X, y, cv=5)\n",
        "    print(f\"C={c}: Mean CV Accuracy = {scores.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZYWtnmLe9W0",
        "outputId": "6576e792-5b85-4111-a707-2ba60a9020fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=0.01: Mean CV Accuracy = 0.7164\n",
            "C=0.1: Mean CV Accuracy = 0.7908\n",
            "C=1: Mean CV Accuracy = 0.7879\n",
            "C=10: Mean CV Accuracy = 0.7879\n",
            "C=100: Mean CV Accuracy = 0.7893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions\n",
        "\n",
        "import joblib\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "joblib.dump(model, 'logistic_model.pkl')\n",
        "loaded_model = joblib.load('logistic_model.pkl')\n",
        "\n",
        "print(f\"Loaded Model Accuracy: {loaded_model.score(X_test, y_test):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nknn_uoFfBHF",
        "outputId": "b87ebfe1-ec06-4c7e-eafe-bb261b734b28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Model Accuracy: 0.7902\n"
          ]
        }
      ]
    }
  ]
}